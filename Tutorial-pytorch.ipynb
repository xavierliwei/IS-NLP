{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0C98yoqr2JV"
   },
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VfxTKyzr2JW"
   },
   "source": [
    "This file is used as a reference to pytorch syntax.\n",
    "\n",
    "Pytorch is a python framework for machine learning\n",
    "\n",
    "- GPU-accelerated computations\n",
    "- automatic differentiation\n",
    "- modules for neural networks\n",
    "\n",
    "This tutorial will teach you the fundamentals of operating on pytorch tensors and networks. You have already seen some things in recitation 0 which we will quickly review, but most of this tutorial is on mostly new or more advanced stuff.\n",
    "\n",
    "For a worked example of how to build and train a pytorch network, see `pytorch-example.ipynb`.\n",
    "\n",
    "For additional tutorials, see http://pytorch.org/tutorials/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1599166421776,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "Wb21_66Ur2JW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1326,
     "status": "ok",
     "timestamp": 1599166222270,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "RP-O-2Aqr2JZ",
    "outputId": "a2cdba99-37f3-4971-d783-d523defe07f1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.6.0+cu101'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5z5CoVzTr2Jc"
   },
   "source": [
    "## Tensors (review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3xsimeBr2Jd"
   },
   "source": [
    "Tensors are the fundamental object for array data. The most common types you will use are `IntTensor` and `FloatTensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1599166222271,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "eWZ7pz9Er2Jd",
    "outputId": "f45a1f8a-8b52-4f63-ff67-ea0be364bce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.6565e-06,  0.0000e+00,  3.7835e-44],\n",
      "        [ 0.0000e+00,         nan,  2.0849e-01]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Create uninitialized tensor\n",
    "x = torch.FloatTensor(2,3)\n",
    "print(x)\n",
    "# Initialize to zeros\n",
    "x.zero_()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1312,
     "status": "ok",
     "timestamp": 1599166222272,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "k1Pioxoer2Jg",
    "outputId": "091194bf-8ba9-43f2-87f3-055afb6d2213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6965, 0.2861, 0.2269],\n",
      "        [0.5513, 0.7195, 0.4231]])\n",
      "tensor([[0.6965, 0.2861, 0.2269],\n",
      "        [0.5513, 0.7195, 0.4231]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Create from numpy array (seed for repeatability)\n",
    "np.random.seed(123)\n",
    "np_array = np.random.random((2,3))\n",
    "print(torch.FloatTensor(np_array))\n",
    "print(torch.from_numpy(np_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1306,
     "status": "ok",
     "timestamp": 1599166222272,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "nHIWJBSrr2Jj",
    "outputId": "dcad42ab-3a8f-4f2f-9a6e-3fdb5f65b556",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1115,  0.1204, -0.3696],\n",
      "        [-0.2404, -1.1969,  0.2093]])\n",
      "[[-0.11146712  0.12036294 -0.3696345 ]\n",
      " [-0.24041797 -1.1969243   0.20926936]]\n"
     ]
    }
   ],
   "source": [
    "# Create random tensor (seed for repeatability)\n",
    "torch.manual_seed(123)\n",
    "x=torch.randn(2,3)\n",
    "print(x)\n",
    "# export to numpy array\n",
    "x_np = x.numpy()\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1300,
     "status": "ok",
     "timestamp": 1599166222273,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "6fZV5O6br2Jm",
    "outputId": "0524810f-6dd2-43ca-de51-bbc2553333e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# special tensors (see documentation)\n",
    "print(torch.eye(3))\n",
    "print(torch.ones(2,3))\n",
    "print(torch.zeros(2,3))\n",
    "print(torch.arange(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U38ubEcNr2Jp"
   },
   "source": [
    "All tensors have a `size` and `type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1599166222274,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "nCirREorr2Jq",
    "outputId": "8f8fa477-da74-49ec-ac0f-c0b5cf1b57b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x=torch.FloatTensor(3,4)\n",
    "print(x.size())\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ks9_voC4r2Jt"
   },
   "source": [
    "## Math, Linear Algebra, and Indexing (review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THc8wy78r2Jt"
   },
   "source": [
    "Pytorch math and linear algebra is similar to numpy. Operators are overridden so you can use standard math operators (`+`,`-`, etc.) and expect a tensor as a result. See pytorch documentation for a complete list of available functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1287,
     "status": "ok",
     "timestamp": 1599166222274,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "PQodhIser2Ju",
    "outputId": "0c41b53d-403b-46d1-aa63-6c4ec912a5df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n",
      "tensor(85.7910)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0.,5.)\n",
    "print(torch.sum(x))\n",
    "print(torch.sum(torch.exp(x)))\n",
    "print(torch.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pjwBteBr2Jx"
   },
   "source": [
    "Pytorch indexing is similar to numpy indexing. See pytorch documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280,
     "status": "ok",
     "timestamp": 1599166222275,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "jmYeDxOAr2Jy",
    "outputId": "e6347c10-e0fc-4b57-d80a-4e20b41dac71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]])\n",
      "tensor([0.3164, 0.4017])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,2)\n",
    "print(x)\n",
    "print(x[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_1cyRkXr2J1"
   },
   "source": [
    "## CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TviqbXWor2J1"
   },
   "source": [
    "Tensors can be copied between CPU and GPU. It is important that everything involved in a calculation is on the same device. \n",
    "\n",
    "This portion of the tutorial may not work for you if you do not have a GPU available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1274,
     "status": "ok",
     "timestamp": 1599166222275,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "9TZDGR3jr2J2"
   },
   "outputs": [],
   "source": [
    "# create a tensor\n",
    "x = torch.rand(3,2)\n",
    "# copy to GPU\n",
    "y = x.cuda()\n",
    "# copy back to CPU\n",
    "z = y.cpu()\n",
    "# get CPU tensor as numpy array\n",
    "# cannot get GPU tensor as numpy array directly\n",
    "try:\n",
    "    y.cpu().numpy()\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLa3pOFzr2J5"
   },
   "source": [
    "Operations between GPU and CPU tensors will fail. Operations require all arguments to be on the same device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1269,
     "status": "ok",
     "timestamp": 1599166222276,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "DHhwnbaTr2J6"
   },
   "outputs": [],
   "source": [
    "x = torch.rand(3,5)  # CPU tensor\n",
    "y = torch.rand(5,4).cuda()  # GPU tensor\n",
    "# try:\n",
    "#     torch.mm(x,y)  # Operation between CPU and GPU fails. Okay, we're not actually going to run this because this casues weird side effects in Colab that break everything else : )\n",
    "# except TypeError as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODn5ODa6r2J9"
   },
   "source": [
    "Typical code should include `if` statements or utilize helper functions so it can operate with or without the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1599166222276,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "hPoukmAor2J9",
    "outputId": "e65ea533-0040-4c22-8c78-0cf5b8049c45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0950, 0.5789],\n",
      "        [0.9131, 0.0275],\n",
      "        [0.1634, 0.3009]], device='cuda:0') torch.float32\n",
      "tensor([[9.0180e-03, 3.3508e-01],\n",
      "        [8.3382e-01, 7.5626e-04],\n",
      "        [2.6693e-02, 9.0521e-02]], device='cuda:0')\n",
      "tensor([[9.0180e-03, 3.3508e-01],\n",
      "        [8.3382e-01, 7.5626e-04],\n",
      "        [2.6693e-02, 9.0521e-02]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Put tensor on CUDA if available\n",
    "x = torch.rand(3,2)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.to(\"cuda:0\")\n",
    "    print(x, x.dtype)\n",
    "    \n",
    "# Do some calculations\n",
    "y = x ** 2 \n",
    "print(y)\n",
    "\n",
    "# Copy to CPU if on GPU\n",
    "if y.is_cuda:\n",
    "    y = y.cpu()\n",
    "    print(y, y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5YkNmi0r2KA"
   },
   "source": [
    "A convenient method is `new`, which creates a new tensor on the same device as another tensor. It should be used for creating tensors whenever possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1251,
     "status": "ok",
     "timestamp": 1599166222277,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "ZTURYratr2KA",
    "outputId": "6f23e320-1598-4c08-c69a-394419bd47f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.6559e-06,  0.0000e+00]])\n",
      "tensor([[0.0090, 0.3351]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(3,2)\n",
    "x2 = x1.new(1,2)  # create cpu tensor\n",
    "print(x2)\n",
    "x1 = torch.rand(3,2).cuda()\n",
    "x2 = x1.new(1,2)  # create cuda tensor\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nvoX6z2gr2KD"
   },
   "source": [
    "Calculations executed on the GPU can be many times faster than numpy. However, numpy is still optimized for the CPU and many times faster than python `for` loops. Numpy calculations may be faster than GPU calculations for small arrays due to the cost of interfacing with the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2114,
     "status": "ok",
     "timestamp": 1599166223147,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "U6dbjMP-r2KE",
    "outputId": "184f7f53-d9d7-46f4-ed48-97e1c683dd77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 670.0546240000449ms\n",
      "GPU: 118.93357199994625ms\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "# Create random data\n",
    "x = torch.rand(1000,64)\n",
    "y = torch.rand(64,32)\n",
    "number = 10000  # number of iterations\n",
    "\n",
    "def square():\n",
    "    z=torch.mm(x, y) # dot product (mm=matrix multiplication)\n",
    "\n",
    "# Time CPU\n",
    "print('CPU: {}ms'.format(timeit(square, number=number)*1000))\n",
    "# Time GPU\n",
    "x, y = x.cuda(), y.cuda()\n",
    "print('GPU: {}ms'.format(timeit(square, number=number)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n6L5DTqCr2KH"
   },
   "source": [
    "## Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGaZKIJ8r2KH"
   },
   "source": [
    "Tensors provide automatic differentiation.\n",
    "\n",
    "As you might know, previous versions of Pytorch used Variables, which were wrappers around tensors for differentiation. Starting with pytorch 0.4.0, this wrapping is done internally in the Tensor class and you can, and should, differentiate Tensors directly. However, it is possible that you walk on references to Variables, e.g. in your error messages.\n",
    "\n",
    "What you need to remember :\n",
    "\n",
    "- Tensors you are differentiating with respect to must have `requires_grad=True`\n",
    "- Call `.backward()` on scalar variables you are differentiating\n",
    "- To differentiate a vector, sum it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2438,
     "status": "error",
     "timestamp": 1599166223479,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "fth20WyJr2KI",
    "outputId": "28584eb2-35a3-4037-ad2f-3c1795829a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d78e2b2ef5ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Calculate gradient (dy/dx=2x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this breaks because requires_grad is FALSE for x, so subsequently for y as well. Try setting it to True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Print values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Create differentiable tensor\n",
    "x = torch.tensor(torch.arange(0,4), requires_grad=False)\n",
    "print(x.dtype)\n",
    "# Calculate y=sum(x**2)\n",
    "y = x**2\n",
    "# Calculate gradient (dy/dx=2x)\n",
    "y.sum().backward() # this breaks because requires_grad is FALSE for x, so subsequently for y as well. Try setting it to True\n",
    "# Print values\n",
    "print(x)\n",
    "print(y)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkxgeD7lr2KN"
   },
   "source": [
    "Differentiation accumulates gradients. This is sometimes what you want and sometimes not. **Make sure to zero gradients between batches if performing gradient descent or you will get strange results!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1599166241347,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "8UxB4KmFr2KN",
    "outputId": "306de91a-0d05-43a1-e09c-207462f6d87b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 4., 6.])\n",
      "tensor([ 0.,  4.,  8., 12.])\n",
      "tensor([0., 2., 4., 6.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create a variable\n",
    "x=torch.tensor(torch.arange(0,4), requires_grad=True, dtype=torch.float)\n",
    "# Differentiate\n",
    "torch.sum(x**2).backward()\n",
    "print(x.grad)\n",
    "# Differentiate again (accumulates gradient)\n",
    "torch.sum(x**2).backward()\n",
    "print(x.grad)\n",
    "# Zero gradient before differentiating\n",
    "x.grad.data.zero_()\n",
    "torch.sum(x**2).backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGWbBhior2KQ"
   },
   "source": [
    "Note that a Tensor with gradient cannot be exported to numpy directly :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 531,
     "status": "error",
     "timestamp": 1599166247068,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "ndOEYbY9r2KQ",
    "outputId": "4435032f-ccf2-4e86-f533-0d4763c03a4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-11ffcfbe0d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# raises an exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "x=torch.tensor(torch.arange(0,4), requires_grad=True, dtype=torch.float)\n",
    "x.numpy() # raises an exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlecNczir2KT"
   },
   "source": [
    "The reason is that pytorch remembers the graph of all computations to perform differenciation. To be integrated to this graph the raw data is wrapped internally to the Tensor class (like what was formerly a Variable). You can detach the tensor from the graph using the **.detach()** method, which returns a tensor with the same data but requires_grad set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1599166247252,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "rFUkhBiqr2KT",
    "outputId": "cf66c138-fb40-4292-952c-660ba7d83f80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., 16., 81.], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor(torch.arange(0,4), requires_grad=True, dtype=torch.float)\n",
    "y=x**2\n",
    "z=y**2\n",
    "z.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1599166247253,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "aD1n2aqcr2KV",
    "outputId": "8f483c5f-f141-46ea-db4e-34aa63f016e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., 16., 81.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you're tired to seeing the warnings above, another way to write it would be\n",
    "x = torch.arange(0,4).float()\n",
    "x.requires_grad = True\n",
    "y = x**2\n",
    "z = y**2\n",
    "z.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVY4A9K2r2KX"
   },
   "source": [
    "Another reason to use this method is that updating the graph can use a lot of memory. If you are in a context where you have a differentiable tensor that you don't need to differentiate, think of detaching it from the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZ01AInyr2KY"
   },
   "source": [
    "## Neural Network Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81qpaYVdr2KY"
   },
   "source": [
    "Pytorch provides a framework for developing neural network modules. They take care of many things, the main one being wrapping and tracking a list of parameters for you.\n",
    "You have several ways of building and using a network, offering different tradeoffs between freedom and simplicity.\n",
    "\n",
    "torch.nn provides basic 1-layer nets, such as Linear (perceptron) and activation layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 693,
     "status": "ok",
     "timestamp": 1599166247253,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "JurRv1aEr2KZ",
    "outputId": "dab5be9a-b6da-489c-e855-5c3bf9af0fac",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-11.2654,  -5.1798, -12.6108,  10.2352,  -0.8935, -16.3450,   0.8731,\n",
      "          8.7567,  15.4684,   2.9802], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0,32).float() # note that we didn't need to set requires_grad=True on the input! \n",
    "net = torch.nn.Linear(32,10)\n",
    "y = net(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xW5wwy4Cr2Kb"
   },
   "source": [
    "All nn.Module objects are reusable as components of bigger networks ! That is how you build personnalized nets. The simplest way is to use the nn.Sequential class.\n",
    "\n",
    "You can also create your own class that inherits n.Module. The forward method should precise what happens in the forward pass given an input. This enables you to precise behaviors more complicated than just applying layers one after another, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1599166247254,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "xz783kUHr2Kb"
   },
   "outputs": [],
   "source": [
    "# create a simple sequential network (`nn.Module` object) from layers (other `nn.Module` objects).\n",
    "# Here a MLP with 2 layers and sigmoid activation.\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(32,128),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(128,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 680,
     "status": "ok",
     "timestamp": 1599166247256,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "-jT-uLOJr2Kg"
   },
   "outputs": [],
   "source": [
    "# create a more customizable network module (equivalent here)\n",
    "class MyNetwork(torch.nn.Module):\n",
    "    # you can use the layer sizes as initialization arguments if you want to\n",
    "    def __init__(self,input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(input_size,hidden_size)\n",
    "        self.layer2 = torch.nn.Sigmoid()\n",
    "        self.layer3 = torch.nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self, input_val):\n",
    "        h = input_val\n",
    "        h = self.layer1(h)\n",
    "        h = self.layer2(h)\n",
    "        h = self.layer3(h)\n",
    "        return h\n",
    "\n",
    "net = MyNetwork(32,128,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQzpr67cr2Kj"
   },
   "source": [
    "The network tracks parameters, and you can access them through the **parameters()** method, which returns a python generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1599166247257,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "ezGf5pN3r2Kj",
    "outputId": "8f2994ed-d359-4b47-a4db-d2ae65e859c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0080, -0.1092, -0.0599,  ..., -0.1456,  0.0865,  0.1176],\n",
      "        [-0.1304,  0.0644, -0.1766,  ..., -0.0393, -0.0157, -0.1341],\n",
      "        [ 0.0140, -0.1288, -0.1243,  ..., -0.1510,  0.0714, -0.0168],\n",
      "        ...,\n",
      "        [ 0.1721,  0.0633,  0.0242,  ...,  0.1268,  0.0177, -0.1755],\n",
      "        [-0.1404, -0.0018, -0.1066,  ...,  0.0408, -0.0123, -0.1635],\n",
      "        [ 0.0330,  0.1358, -0.1656,  ..., -0.0513, -0.0271, -0.0602]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1677,  0.0115, -0.0710, -0.0480,  0.0504,  0.0364,  0.1576, -0.0507,\n",
      "         0.1083, -0.1162, -0.0565, -0.0122,  0.0131,  0.0323, -0.1086,  0.1145,\n",
      "         0.1153,  0.1578, -0.1741, -0.0879, -0.1259,  0.1038, -0.1328,  0.1236,\n",
      "         0.0834,  0.1593,  0.1020, -0.1573, -0.0994, -0.0793,  0.0433, -0.0659,\n",
      "        -0.0446, -0.1097, -0.0849, -0.1697, -0.1460,  0.1269,  0.0598,  0.0937,\n",
      "         0.1518, -0.1610,  0.0869, -0.1608, -0.1033,  0.0641, -0.0692, -0.1414,\n",
      "         0.1670, -0.0994,  0.0192, -0.0146, -0.0799, -0.0333,  0.1528, -0.0130,\n",
      "         0.1032,  0.1355, -0.1415, -0.1337,  0.0166,  0.1482,  0.1602, -0.0959,\n",
      "        -0.0823,  0.1096,  0.0286, -0.1467,  0.0226, -0.1740,  0.1762,  0.1307,\n",
      "         0.0437,  0.0863, -0.1170,  0.0367, -0.1560,  0.0085, -0.0489, -0.1354,\n",
      "         0.1188, -0.1400, -0.1756, -0.1462,  0.0477,  0.0354,  0.1381, -0.1254,\n",
      "         0.0803, -0.1199, -0.1253,  0.1687,  0.1177, -0.0132, -0.1615, -0.1667,\n",
      "         0.1310,  0.1598, -0.0513,  0.0045,  0.0911,  0.1045,  0.1245, -0.0221,\n",
      "         0.1442, -0.1270, -0.1057,  0.1460, -0.0585, -0.0817, -0.0719, -0.0554,\n",
      "         0.0075, -0.0454, -0.1012,  0.0224,  0.1431, -0.1407, -0.0969, -0.1543,\n",
      "        -0.0744,  0.0782, -0.0643, -0.1219, -0.0853,  0.1137, -0.0282,  0.0525],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0777, -0.0082,  0.0692,  ..., -0.0850, -0.0309,  0.0244],\n",
      "        [ 0.0619, -0.0050, -0.0877,  ...,  0.0073,  0.0398, -0.0094],\n",
      "        [ 0.0153, -0.0798,  0.0205,  ...,  0.0096,  0.0183,  0.0260],\n",
      "        ...,\n",
      "        [ 0.0457,  0.0519,  0.0702,  ..., -0.0250,  0.0832,  0.0561],\n",
      "        [ 0.0400, -0.0487, -0.0225,  ..., -0.0002,  0.0139, -0.0730],\n",
      "        [ 0.0540, -0.0049,  0.0688,  ...,  0.0765,  0.0880, -0.0761]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0156,  0.0503,  0.0099,  0.0750,  0.0788,  0.0486,  0.0794,  0.0333,\n",
      "         0.0024, -0.0760], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfD9h40Yr2Km"
   },
   "source": [
    "Parameters are of type Parameter, which is basically a wrapper for a tensor. How does pytorch retrieve your network's parameters ? They are simply all the attributes of type Parameter in your network. Moreover, if an attribute is of type nn.Module, its own parameters are added to your network's parameters ! This is why, when you define a network by adding up basic components such as nn.Linear, you should never have to explicitely define parameters.\n",
    "\n",
    "However, if you are in a case where no pytorch default module does what you need, you can define parameters explicitely (this should be rare). For the record, let's build the previous MLP with personnalized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 663,
     "status": "ok",
     "timestamp": 1599166247257,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "XJTy-rNvr2Km"
   },
   "outputs": [],
   "source": [
    "class MyNetworkWithParams(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, output_size):\n",
    "        super(MyNetworkWithParams,self).__init__()\n",
    "        self.layer1_weights = nn.Parameter(torch.randn(input_size,hidden_size))\n",
    "        self.layer1_bias = nn.Parameter(torch.randn(hidden_size))\n",
    "        self.layer2_weights = nn.Parameter(torch.randn(hidden_size,output_size))\n",
    "        self.layer2_bias = nn.Parameter(torch.randn(output_size))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h1 = torch.matmul(x,self.layer1_weights) + self.layer1_bias\n",
    "        h1_act = torch.max(h1, torch.zeros(h1.size())) # ReLU\n",
    "        output = torch.matmul(h1_act,self.layer2_weights) + self.layer2_bias\n",
    "        return output\n",
    "\n",
    "net = MyNetworkWithParams(32,128,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cjBEhFPIr2Kp"
   },
   "source": [
    "Parameters are useful in that they are meant to be all the network's weights that will be optimized during training. If you were needing to use a tensor in your computational graph that you want to remain constant, just define it as a regular tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlO8kwqGr2Kp"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1599166247258,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "I1Qf9UHvr2Kq"
   },
   "outputs": [],
   "source": [
    "net = MyNetwork(32,128,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DbqZItt8r2Ks"
   },
   "source": [
    "The nn.Module also provides loss functions, such as cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1599166247259,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "Vik4g78Er2Kt",
    "outputId": "42196b10-f0d4-4076-e70d-465f8d0eb068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4213, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([np.arange(32), np.zeros(32),np.ones(32)]).float()\n",
    "y = torch.tensor([0,3,9])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "output = net(x)\n",
    "loss = criterion(output,y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCvNflwur2Kw"
   },
   "source": [
    "nn.CrossEntropyLoss does both the softmax and the actual cross-entropy : given $output$ of size $(n,d)$ and $y$ of size $n$ and values in $0,1,...,d-1$, it computes $\\sum_{i=0}^{n-1}log(s[i,y[i]])$ where $s[i,j] = \\frac{e^{output[i,j]}}{\\sum_{j'=0}^{d-1}e^{output[i,j']}}$\n",
    "\n",
    "You can also compose nn.LogSoftmax and nn.NLLLoss to get the same result. Note that all these use the log-softmax rather than the softmax, for stability in the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1599166247259,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "FDCcOxCXr2Kw",
    "outputId": "4ba8fd9a-20c2-42ad-d12b-0fce068e5e5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.4213, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalent\n",
    "criterion2 = nn.NLLLoss()\n",
    "sf = nn.LogSoftmax()\n",
    "output = net(x)\n",
    "loss = criterion(sf(output),y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kze7FJsZr2Kz"
   },
   "source": [
    "Now, to perform the backward pass, just execute **loss.backward()** ! It will update gradients in all differentiable tensors in the graph, which in particular includes all the network parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1599166247260,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "yn6YY3EOr2Kz",
    "outputId": "3495a0f1-8fd6-4770-9560-bda6c3cff2d4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
      "        [-0.0037, -0.0037, -0.0037,  ..., -0.0037, -0.0037, -0.0037],\n",
      "        [-0.0078, -0.0078, -0.0078,  ..., -0.0074, -0.0074, -0.0074],\n",
      "        ...,\n",
      "        [-0.0040, -0.0040, -0.0040,  ..., -0.0045, -0.0046, -0.0046],\n",
      "        [ 0.0038,  0.0038,  0.0038,  ...,  0.0038,  0.0038,  0.0038],\n",
      "        [-0.0029, -0.0047, -0.0066,  ..., -0.0569, -0.0587, -0.0606]])\n",
      "tensor([-9.4054e-04, -6.1805e-03, -1.2012e-02,  9.7801e-03,  1.1470e-03,\n",
      "         6.0123e-03,  1.8151e-03,  3.6971e-03, -8.1812e-03, -3.9692e-03,\n",
      "         6.5300e-04, -9.2533e-03, -1.8172e-03,  2.0503e-03,  4.2377e-04,\n",
      "         4.4279e-03, -4.0830e-03, -1.2903e-02, -7.1773e-03,  9.7517e-04,\n",
      "         5.7179e-03,  8.3892e-03,  7.8087e-04, -1.7488e-03,  2.3776e-03,\n",
      "        -4.1248e-03, -2.3352e-03, -6.4370e-04,  1.1360e-03, -4.4238e-03,\n",
      "        -2.9335e-03, -5.9201e-03,  1.1329e-04, -4.7018e-03,  1.9633e-03,\n",
      "         4.3207e-04,  3.1228e-03,  4.5239e-03,  2.5811e-03,  2.1374e-03,\n",
      "        -3.0686e-03, -2.9969e-03, -1.5206e-03, -1.0799e-03,  6.1311e-03,\n",
      "        -2.8670e-03,  5.8701e-03, -2.9298e-03,  4.0113e-03, -8.3163e-03,\n",
      "         1.0836e-02,  2.5772e-03,  6.0148e-03,  1.3243e-04, -2.6472e-04,\n",
      "        -7.2312e-03, -3.5201e-03, -2.4451e-03,  1.6987e-03,  7.8412e-04,\n",
      "        -1.8517e-04,  7.5335e-03,  3.0189e-03, -8.1852e-03,  6.7363e-04,\n",
      "         1.1534e-02,  7.5467e-03,  4.1113e-03, -1.4041e-03,  1.0736e-03,\n",
      "        -7.1668e-04,  5.6191e-03,  4.0703e-03,  8.1710e-03, -4.7825e-03,\n",
      "        -3.1330e-03,  1.3513e-02,  6.5572e-03,  8.1892e-03, -1.2582e-02,\n",
      "         3.0075e-04,  6.8713e-03,  9.1457e-04,  5.9622e-03,  6.5552e-03,\n",
      "        -6.0362e-04,  1.3787e-02, -5.7279e-03,  1.1425e-02, -3.6415e-03,\n",
      "        -5.4924e-03,  4.4292e-03, -3.9680e-03,  1.0910e-02, -3.0437e-03,\n",
      "        -9.7337e-03,  8.1788e-03,  2.2185e-04, -1.1435e-02, -8.4914e-04,\n",
      "        -7.6955e-03,  2.1921e-03, -1.0850e-04,  1.3853e-02, -4.4513e-03,\n",
      "         9.6455e-03, -1.8655e-03,  8.3718e-04,  5.1500e-03,  6.0772e-04,\n",
      "         7.9334e-03, -2.5124e-03,  5.2713e-03,  1.3993e-05, -8.7995e-03,\n",
      "         9.1346e-03, -1.0821e-03,  9.5218e-03,  4.1316e-03,  8.2272e-03,\n",
      "        -5.7963e-04,  9.6577e-03,  8.4036e-03,  4.5100e-03, -2.6752e-03,\n",
      "        -4.7328e-03,  9.5323e-04, -1.0732e-02])\n",
      "tensor([[ 0.0369,  0.0395, -0.2244,  ...,  0.0469, -0.2168, -0.1390],\n",
      "        [ 0.0314,  0.0337,  0.1213,  ...,  0.0412,  0.1285,  0.0955],\n",
      "        [ 0.0189,  0.0203,  0.0594,  ...,  0.0247,  0.0636,  0.0482],\n",
      "        ...,\n",
      "        [ 0.0158,  0.0169,  0.0377,  ...,  0.0201,  0.0409,  0.0320],\n",
      "        [ 0.0233,  0.0250,  0.0695,  ...,  0.0301,  0.0745,  0.0568],\n",
      "        [-0.0452, -0.0563, -0.1457,  ..., -0.1080, -0.1840, -0.1240]])\n",
      "tensor([-0.1760,  0.1636,  0.0848, -0.2584,  0.1230,  0.0619,  0.1022,  0.0583,\n",
      "         0.1003, -0.2597])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "\n",
    "# Check that the parameters now have gradients\n",
    "for param in net.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1599166247260,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "D39UGVwHr2K2",
    "outputId": "8fb11666-9650-4538-9f52-ae6a981b601b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        [-0.0073, -0.0073, -0.0073,  ..., -0.0073, -0.0073, -0.0073],\n",
      "        [-0.0156, -0.0156, -0.0155,  ..., -0.0148, -0.0148, -0.0148],\n",
      "        ...,\n",
      "        [-0.0079, -0.0080, -0.0080,  ..., -0.0091, -0.0091, -0.0092],\n",
      "        [ 0.0075,  0.0075,  0.0075,  ...,  0.0075,  0.0075,  0.0075],\n",
      "        [-0.0058, -0.0095, -0.0132,  ..., -0.1137, -0.1174, -0.1212]])\n",
      "tensor([-1.8811e-03, -1.2361e-02, -2.4024e-02,  1.9560e-02,  2.2940e-03,\n",
      "         1.2025e-02,  3.6301e-03,  7.3943e-03, -1.6362e-02, -7.9383e-03,\n",
      "         1.3060e-03, -1.8507e-02, -3.6345e-03,  4.1006e-03,  8.4755e-04,\n",
      "         8.8559e-03, -8.1659e-03, -2.5805e-02, -1.4355e-02,  1.9503e-03,\n",
      "         1.1436e-02,  1.6778e-02,  1.5617e-03, -3.4975e-03,  4.7552e-03,\n",
      "        -8.2496e-03, -4.6704e-03, -1.2874e-03,  2.2720e-03, -8.8477e-03,\n",
      "        -5.8670e-03, -1.1840e-02,  2.2658e-04, -9.4036e-03,  3.9265e-03,\n",
      "         8.6415e-04,  6.2455e-03,  9.0478e-03,  5.1621e-03,  4.2748e-03,\n",
      "        -6.1372e-03, -5.9938e-03, -3.0411e-03, -2.1599e-03,  1.2262e-02,\n",
      "        -5.7340e-03,  1.1740e-02, -5.8596e-03,  8.0225e-03, -1.6633e-02,\n",
      "         2.1673e-02,  5.1545e-03,  1.2030e-02,  2.6486e-04, -5.2944e-04,\n",
      "        -1.4462e-02, -7.0402e-03, -4.8903e-03,  3.3974e-03,  1.5682e-03,\n",
      "        -3.7034e-04,  1.5067e-02,  6.0378e-03, -1.6370e-02,  1.3473e-03,\n",
      "         2.3069e-02,  1.5093e-02,  8.2227e-03, -2.8082e-03,  2.1471e-03,\n",
      "        -1.4334e-03,  1.1238e-02,  8.1406e-03,  1.6342e-02, -9.5651e-03,\n",
      "        -6.2661e-03,  2.7025e-02,  1.3114e-02,  1.6378e-02, -2.5164e-02,\n",
      "         6.0150e-04,  1.3743e-02,  1.8291e-03,  1.1924e-02,  1.3110e-02,\n",
      "        -1.2072e-03,  2.7575e-02, -1.1456e-02,  2.2851e-02, -7.2829e-03,\n",
      "        -1.0985e-02,  8.8584e-03, -7.9360e-03,  2.1820e-02, -6.0874e-03,\n",
      "        -1.9467e-02,  1.6358e-02,  4.4371e-04, -2.2869e-02, -1.6983e-03,\n",
      "        -1.5391e-02,  4.3842e-03, -2.1699e-04,  2.7706e-02, -8.9027e-03,\n",
      "         1.9291e-02, -3.7309e-03,  1.6744e-03,  1.0300e-02,  1.2154e-03,\n",
      "         1.5867e-02, -5.0248e-03,  1.0543e-02,  2.7986e-05, -1.7599e-02,\n",
      "         1.8269e-02, -2.1642e-03,  1.9044e-02,  8.2633e-03,  1.6454e-02,\n",
      "        -1.1593e-03,  1.9315e-02,  1.6807e-02,  9.0199e-03, -5.3503e-03,\n",
      "        -9.4655e-03,  1.9065e-03, -2.1464e-02])\n",
      "tensor([[ 0.0738,  0.0790, -0.4487,  ...,  0.0937, -0.4335, -0.2780],\n",
      "        [ 0.0627,  0.0674,  0.2427,  ...,  0.0824,  0.2569,  0.1910],\n",
      "        [ 0.0379,  0.0407,  0.1188,  ...,  0.0494,  0.1273,  0.0964],\n",
      "        ...,\n",
      "        [ 0.0316,  0.0338,  0.0755,  ...,  0.0401,  0.0819,  0.0640],\n",
      "        [ 0.0466,  0.0500,  0.1390,  ...,  0.0601,  0.1489,  0.1135],\n",
      "        [-0.0905, -0.1125, -0.2915,  ..., -0.2160, -0.3680, -0.2480]])\n",
      "tensor([-0.3519,  0.3272,  0.1695, -0.5168,  0.2460,  0.1237,  0.2045,  0.1166,\n",
      "         0.2006, -0.5193])\n",
      "tensor([[ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
      "        [-0.0037, -0.0037, -0.0037,  ..., -0.0037, -0.0037, -0.0037],\n",
      "        [-0.0078, -0.0078, -0.0078,  ..., -0.0074, -0.0074, -0.0074],\n",
      "        ...,\n",
      "        [-0.0040, -0.0040, -0.0040,  ..., -0.0045, -0.0046, -0.0046],\n",
      "        [ 0.0038,  0.0038,  0.0038,  ...,  0.0038,  0.0038,  0.0038],\n",
      "        [-0.0029, -0.0047, -0.0066,  ..., -0.0569, -0.0587, -0.0606]])\n",
      "tensor([-9.4054e-04, -6.1805e-03, -1.2012e-02,  9.7801e-03,  1.1470e-03,\n",
      "         6.0123e-03,  1.8151e-03,  3.6971e-03, -8.1812e-03, -3.9692e-03,\n",
      "         6.5300e-04, -9.2533e-03, -1.8172e-03,  2.0503e-03,  4.2377e-04,\n",
      "         4.4279e-03, -4.0830e-03, -1.2903e-02, -7.1773e-03,  9.7517e-04,\n",
      "         5.7179e-03,  8.3892e-03,  7.8087e-04, -1.7488e-03,  2.3776e-03,\n",
      "        -4.1248e-03, -2.3352e-03, -6.4370e-04,  1.1360e-03, -4.4238e-03,\n",
      "        -2.9335e-03, -5.9201e-03,  1.1329e-04, -4.7018e-03,  1.9633e-03,\n",
      "         4.3207e-04,  3.1228e-03,  4.5239e-03,  2.5811e-03,  2.1374e-03,\n",
      "        -3.0686e-03, -2.9969e-03, -1.5206e-03, -1.0799e-03,  6.1311e-03,\n",
      "        -2.8670e-03,  5.8701e-03, -2.9298e-03,  4.0113e-03, -8.3163e-03,\n",
      "         1.0836e-02,  2.5772e-03,  6.0148e-03,  1.3243e-04, -2.6472e-04,\n",
      "        -7.2312e-03, -3.5201e-03, -2.4451e-03,  1.6987e-03,  7.8412e-04,\n",
      "        -1.8517e-04,  7.5335e-03,  3.0189e-03, -8.1852e-03,  6.7363e-04,\n",
      "         1.1534e-02,  7.5467e-03,  4.1113e-03, -1.4041e-03,  1.0736e-03,\n",
      "        -7.1668e-04,  5.6191e-03,  4.0703e-03,  8.1710e-03, -4.7825e-03,\n",
      "        -3.1330e-03,  1.3513e-02,  6.5572e-03,  8.1892e-03, -1.2582e-02,\n",
      "         3.0075e-04,  6.8713e-03,  9.1457e-04,  5.9622e-03,  6.5552e-03,\n",
      "        -6.0362e-04,  1.3787e-02, -5.7279e-03,  1.1425e-02, -3.6415e-03,\n",
      "        -5.4924e-03,  4.4292e-03, -3.9680e-03,  1.0910e-02, -3.0437e-03,\n",
      "        -9.7337e-03,  8.1788e-03,  2.2185e-04, -1.1435e-02, -8.4914e-04,\n",
      "        -7.6955e-03,  2.1921e-03, -1.0850e-04,  1.3853e-02, -4.4513e-03,\n",
      "         9.6455e-03, -1.8655e-03,  8.3718e-04,  5.1500e-03,  6.0772e-04,\n",
      "         7.9334e-03, -2.5124e-03,  5.2713e-03,  1.3993e-05, -8.7995e-03,\n",
      "         9.1346e-03, -1.0821e-03,  9.5218e-03,  4.1316e-03,  8.2272e-03,\n",
      "        -5.7963e-04,  9.6577e-03,  8.4036e-03,  4.5100e-03, -2.6752e-03,\n",
      "        -4.7328e-03,  9.5323e-04, -1.0732e-02])\n",
      "tensor([[ 0.0369,  0.0395, -0.2244,  ...,  0.0469, -0.2168, -0.1390],\n",
      "        [ 0.0314,  0.0337,  0.1213,  ...,  0.0412,  0.1285,  0.0955],\n",
      "        [ 0.0189,  0.0203,  0.0594,  ...,  0.0247,  0.0636,  0.0482],\n",
      "        ...,\n",
      "        [ 0.0158,  0.0169,  0.0377,  ...,  0.0201,  0.0409,  0.0320],\n",
      "        [ 0.0233,  0.0250,  0.0695,  ...,  0.0301,  0.0745,  0.0568],\n",
      "        [-0.0452, -0.0563, -0.1457,  ..., -0.1080, -0.1840, -0.1240]])\n",
      "tensor([-0.1760,  0.1636,  0.0848, -0.2584,  0.1230,  0.0619,  0.1022,  0.0583,\n",
      "         0.1003, -0.2597])\n"
     ]
    }
   ],
   "source": [
    "# if I forward prop and backward prop again, gradients accumulate :\n",
    "output = net(x)\n",
    "loss = criterion(output,y)\n",
    "loss.backward()\n",
    "for param in net.parameters():\n",
    "    print(param.grad)\n",
    "\n",
    "# you can remove this behavior by reinitializing the gradients in your network parameters :\n",
    "net.zero_grad()\n",
    "output = net(x)\n",
    "loss = criterion(output,y)\n",
    "loss.backward()\n",
    "for param in net.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSR1DzOgr2K4"
   },
   "source": [
    "We did backpropagation, but still didn't perform gradient descent. Let's define an optimizer on the network parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1599166247366,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "IFTG3kkAr2K4",
    "outputId": "ac970b14-942b-4efe-c3c1-88d83bac7c0d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters before gradient descent :\n",
      "Parameter containing:\n",
      "tensor([[-0.1304,  0.0003, -0.1563,  ..., -0.1631, -0.0063, -0.1529],\n",
      "        [-0.0755,  0.0227, -0.1221,  ...,  0.0014, -0.0819,  0.0647],\n",
      "        [-0.0004,  0.1718,  0.0688,  ..., -0.0230, -0.0616,  0.1032],\n",
      "        ...,\n",
      "        [-0.0620,  0.1712, -0.0744,  ..., -0.1489,  0.0763, -0.0951],\n",
      "        [-0.1070,  0.0719,  0.1619,  ...,  0.1180,  0.0759,  0.0698],\n",
      "        [-0.1238,  0.1715, -0.1681,  ...,  0.0952,  0.0341, -0.0457]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0309,  0.0196,  0.0274, -0.1702, -0.0458,  0.0352, -0.1366,  0.1607,\n",
      "        -0.1137, -0.0695,  0.0403,  0.0866, -0.0381, -0.0676, -0.1215,  0.1454,\n",
      "         0.1548,  0.0473,  0.0093, -0.0777,  0.1307,  0.0738,  0.0428, -0.0367,\n",
      "         0.1464,  0.1611,  0.0209,  0.0431, -0.1234, -0.0167,  0.1560, -0.0413,\n",
      "        -0.1622,  0.1103, -0.0161, -0.0406, -0.0504,  0.0779,  0.0155,  0.0946,\n",
      "         0.0614, -0.1548,  0.0500, -0.1348,  0.0805, -0.0520,  0.0702, -0.1589,\n",
      "         0.0230,  0.1121, -0.0054, -0.0841, -0.0954,  0.1534,  0.1668,  0.0355,\n",
      "        -0.1320,  0.0758,  0.0252, -0.1717, -0.1480,  0.1100, -0.0301, -0.1244,\n",
      "         0.0388,  0.1223,  0.1289, -0.0404,  0.0010,  0.1011, -0.0074,  0.1627,\n",
      "         0.1615, -0.1063, -0.0807,  0.0380, -0.0965, -0.0350, -0.0039, -0.0983,\n",
      "        -0.0435, -0.0097, -0.0312, -0.1722,  0.0109,  0.0997, -0.0460,  0.0446,\n",
      "         0.0779,  0.0752,  0.0099, -0.1635, -0.1513, -0.1321, -0.0327, -0.1355,\n",
      "         0.0731,  0.0599, -0.1695, -0.1178,  0.0159,  0.0258, -0.1056, -0.1238,\n",
      "        -0.0915,  0.0889,  0.1685,  0.0304,  0.0478,  0.1049,  0.0916,  0.1560,\n",
      "         0.1470,  0.0880, -0.0451,  0.0965, -0.1220, -0.1361, -0.1619,  0.0362,\n",
      "         0.0510,  0.0733,  0.0527,  0.1688,  0.1271, -0.0429,  0.1150,  0.0908],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0577,  0.0084, -0.0762,  ...,  0.0510, -0.0873,  0.0345],\n",
      "        [ 0.0050, -0.0036, -0.0612,  ...,  0.0342,  0.0763,  0.0154],\n",
      "        [ 0.0605,  0.0640, -0.0254,  ..., -0.0883, -0.0395, -0.0477],\n",
      "        ...,\n",
      "        [ 0.0659,  0.0722, -0.0156,  ...,  0.0793, -0.0609, -0.0768],\n",
      "        [-0.0208, -0.0054,  0.0676,  ...,  0.0195, -0.0518, -0.0176],\n",
      "        [-0.0270,  0.0721,  0.0792,  ...,  0.0652, -0.0684,  0.0394]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0191, -0.0228,  0.0752, -0.0549, -0.0732, -0.0770,  0.0408,  0.0389,\n",
      "         0.0871, -0.0852], requires_grad=True)\n",
      "Parameters after gradient descent :\n",
      "Parameter containing:\n",
      "tensor([[-0.1304,  0.0003, -0.1563,  ..., -0.1631, -0.0064, -0.1529],\n",
      "        [-0.0755,  0.0227, -0.1221,  ...,  0.0015, -0.0818,  0.0648],\n",
      "        [-0.0003,  0.1719,  0.0688,  ..., -0.0230, -0.0615,  0.1032],\n",
      "        ...,\n",
      "        [-0.0620,  0.1713, -0.0744,  ..., -0.1489,  0.0763, -0.0951],\n",
      "        [-0.1070,  0.0718,  0.1619,  ...,  0.1180,  0.0759,  0.0698],\n",
      "        [-0.1238,  0.1715, -0.1680,  ...,  0.0958,  0.0347, -0.0451]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0308,  0.0196,  0.0275, -0.1703, -0.0458,  0.0352, -0.1366,  0.1607,\n",
      "        -0.1136, -0.0694,  0.0403,  0.0867, -0.0381, -0.0676, -0.1215,  0.1454,\n",
      "         0.1549,  0.0474,  0.0094, -0.0777,  0.1306,  0.0737,  0.0428, -0.0367,\n",
      "         0.1463,  0.1611,  0.0210,  0.0431, -0.1234, -0.0166,  0.1561, -0.0413,\n",
      "        -0.1622,  0.1104, -0.0161, -0.0406, -0.0505,  0.0778,  0.0155,  0.0946,\n",
      "         0.0615, -0.1548,  0.0500, -0.1348,  0.0805, -0.0520,  0.0702, -0.1589,\n",
      "         0.0229,  0.1122, -0.0055, -0.0842, -0.0954,  0.1534,  0.1668,  0.0356,\n",
      "        -0.1319,  0.0758,  0.0251, -0.1717, -0.1480,  0.1099, -0.0301, -0.1244,\n",
      "         0.0387,  0.1222,  0.1288, -0.0405,  0.0010,  0.1011, -0.0074,  0.1627,\n",
      "         0.1615, -0.1064, -0.0806,  0.0381, -0.0966, -0.0351, -0.0040, -0.0981,\n",
      "        -0.0435, -0.0098, -0.0312, -0.1723,  0.0108,  0.0997, -0.0462,  0.0447,\n",
      "         0.0778,  0.0752,  0.0099, -0.1635, -0.1513, -0.1322, -0.0327, -0.1354,\n",
      "         0.0730,  0.0599, -0.1694, -0.1178,  0.0160,  0.0258, -0.1056, -0.1240,\n",
      "        -0.0914,  0.0888,  0.1685,  0.0304,  0.0478,  0.1049,  0.0916,  0.1560,\n",
      "         0.1469,  0.0880, -0.0450,  0.0965, -0.1220, -0.1362, -0.1620,  0.0361,\n",
      "         0.0510,  0.0732,  0.0526,  0.1688,  0.1271, -0.0428,  0.1150,  0.0909],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0580,  0.0080, -0.0739,  ...,  0.0505, -0.0851,  0.0359],\n",
      "        [ 0.0047, -0.0040, -0.0625,  ...,  0.0337,  0.0750,  0.0144],\n",
      "        [ 0.0603,  0.0638, -0.0260,  ..., -0.0885, -0.0401, -0.0482],\n",
      "        ...,\n",
      "        [ 0.0657,  0.0720, -0.0159,  ...,  0.0791, -0.0613, -0.0771],\n",
      "        [-0.0210, -0.0056,  0.0670,  ...,  0.0192, -0.0526, -0.0181],\n",
      "        [-0.0266,  0.0727,  0.0807,  ...,  0.0662, -0.0665,  0.0406]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0209, -0.0244,  0.0743, -0.0523, -0.0744, -0.0776,  0.0398,  0.0383,\n",
      "         0.0861, -0.0826], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Parameters before gradient descent :\")\n",
    "for param in net.parameters():\n",
    "    print(param)\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "print(\"Parameters after gradient descent :\")\n",
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1874,
     "status": "ok",
     "timestamp": 1599166248522,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "-jNhKJBDr2K7",
    "outputId": "d7ec4725-41cf-4d8d-9b4a-8666e436b968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2979, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1852, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0829, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9909, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9084, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8343, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7671, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7059, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6498, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5982, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5504, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5062, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4650, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4266, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3907, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3570, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3254, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2957, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2677, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2412, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2162, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1924, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1700, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1486, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1283, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1090, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0906, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0729, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0561, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0400, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0245, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0097, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9954, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9817, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9316, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8984, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8880, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8780, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8682, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8588, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8496, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8320, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8155, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8075, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7998, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7923, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7849, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7778, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7640, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7574, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7384, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7324, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7265, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7207, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7151, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7096, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7042, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6989, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6887, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6838, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6789, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6742, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6695, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6650, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6605, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6561, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6518, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6393, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6353, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6313, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6274, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6089, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5985, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5952, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5918, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5886, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5822, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5790, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5759, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5699, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5669, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5640, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5582, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5554, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5526, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5418, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5392, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5340, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5315, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5290, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5265, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5241, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5169, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5146, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4989, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4967, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4946, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4925, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4904, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4883, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4842, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4822, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4802, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4782, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4763, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4743, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4667, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4648, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4630, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4612, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4594, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4576, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4540, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4523, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4505, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4488, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4454, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4403, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4354, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4338, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4322, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4306, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4290, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4259, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4243, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4183, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4168, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4153, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4123, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4109, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4094, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4066, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3995, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3968, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3954, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3941, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3927, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3914, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3901, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3887, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3874, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3861, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3848, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3835, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3822, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3810, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3797, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3784, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3772, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3759, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3747, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3734, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3722, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3698, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3685, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3673, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3661, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3650, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3638, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3626, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3614, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3602, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3591, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3579, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3568, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3534, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3522, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3511, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3500, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3489, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3478, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3456, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3412, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3391, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3359, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3349, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3338, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3328, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3318, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3307, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3277, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3267, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3257, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3227, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3207, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3197, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3188, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3168, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3159, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3140, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3130, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3121, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3102, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3083, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3074, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3056, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3028, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2983, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2975, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2966, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2957, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2948, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2931, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2922, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2914, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2905, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2897, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2888, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2880, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2871, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2846, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2838, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2830, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2821, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2813, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2805, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2797, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2789, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2781, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2773, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2765, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2757, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2725, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2717, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2702, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2694, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2679, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2671, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2663, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2648, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2641, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2633, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2626, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2618, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2603, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2596, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2589, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2581, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2574, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2567, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2560, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2552, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2538, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2531, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2524, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2517, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2510, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2496, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2489, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2482, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2461, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2455, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2441, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2428, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2414, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2401, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2388, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2381, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2375, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2362, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2355, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2349, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2342, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2336, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2330, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2317, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2311, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2304, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2298, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2292, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2273, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2267, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2255, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2243, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2231, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2225, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2219, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2207, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2201, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2161, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2155, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2144, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2132, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2127, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2121, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2110, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2099, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2072, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2066, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2055, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2050, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2045, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2034, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1998, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1993, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1977, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1972, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1967, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1962, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1957, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1952, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1942, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1937, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1932, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1927, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1922, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1918, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1913, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1908, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1903, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1898, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1894, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1889, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1884, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1879, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1875, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1865, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1851, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1847, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1842, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1837, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1833, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1828, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1815, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1810, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1806, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1801, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1797, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1792, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1788, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1784, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1779, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1770, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1766, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1762, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1757, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1753, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1745, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1740, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1736, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1732, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1719, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1703, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1699, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1695, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1690, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1682, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1678, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1674, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1670, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1666, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1662, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1658, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1654, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1650, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1647, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1643, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1639, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1635, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1631, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1627, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1623, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1619, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1616, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1612, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1608, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1600, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1597, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1593, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1589, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1586, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1582, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1578, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1574, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1571, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1567, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1563, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1560, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1553, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1549, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1542, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1538, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1535, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1531, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1528, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1524, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1521, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1517, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1514, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1510, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1507, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1500, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1497, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1490, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1486, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1483, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1480, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1463, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1456, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1450, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1440, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1427, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1424, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1418, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1415, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1412, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1408, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1405, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1399, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1396, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1393, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1390, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1384, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1381, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1375, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1372, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1369, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1363, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1360, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1357, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1354, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1351, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1348, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1345, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1342, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1339, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1336, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1334, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1331, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1328, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1325, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1322, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1319, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1317, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1314, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1311, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1308, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1303, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1294, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1292, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1289, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1283, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1278, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1273, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1270, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1267, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1265, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1259, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1257, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1254, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1251, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1244, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1241, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1238, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1231, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1223, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1221, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1211, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1208, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1206, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1203, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1201, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1189, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1186, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1179, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1177, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1170, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1167, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1165, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1163, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1160, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1156, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1153, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1151, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1146, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1144, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1142, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1140, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1137, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1135, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1131, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1120, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1117, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1113, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1109, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1107, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1102, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1098, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1096, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1094, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1092, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1089, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1087, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1083, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1079, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1075, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1071, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1063, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1055, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1049, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1047, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1045, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1035, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1033, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1027, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1001, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0999, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0997, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0995, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0993, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0990, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0988, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0984, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0983, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0981, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0979, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0977, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0976, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0974, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0972, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0970, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0968, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0967, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0965, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0962, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0960, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0958, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0956, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0955, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0953, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0951, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0950, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0948, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0946, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0944, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0943, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0941, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0939, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0936, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0934, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0933, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0931, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0930, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0928, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0926, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0925, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0923, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0921, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0920, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0918, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0917, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0915, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0913, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0912, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0910, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0909, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0907, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0906, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0904, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0902, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0901, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0899, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0898, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0896, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0895, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0893, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0892, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0890, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0889, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0887, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0885, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0884, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0882, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0881, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0879, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0878, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0876, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0875, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0873, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0872, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0871, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0869, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0868, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0866, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0865, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0852, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0850, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0849, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0847, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0846, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0845, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0843, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0842, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0840, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0839, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0838, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0836, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0835, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0834, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0832, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0831, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0829, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0828, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0827, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0825, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0823, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0821, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0820, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0817, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0816, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0815, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0813, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0812, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0811, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0809, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0808, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0807, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0806, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0804, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0803, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0802, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0800, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0799, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0798, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0797, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0795, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0794, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0793, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0791, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0790, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0789, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0788, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0786, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0785, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0784, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0783, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0782, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0780, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0779, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0778, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0777, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0774, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0773, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0772, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0771, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0769, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0768, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0767, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0766, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0765, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0763, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0762, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0761, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0760, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0759, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0757, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0756, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0755, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0753, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0752, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0750, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0748, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0747, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0746, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0745, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0744, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0742, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0740, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0739, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0738, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0737, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0736, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0732, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0730, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0727, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0726, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0725, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0723, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0721, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0720, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0719, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0718, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0717, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0716, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0714, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0713, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0712, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0704, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0703, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0702, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0701, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0700, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0699, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0698, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0696, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0695, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0694, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0693, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0692, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0691, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0690, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0689, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0688, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0687, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0686, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0685, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0684, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0682, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0681, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0680, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0679, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0678, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0677, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0676, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0675, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0674, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0673, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0673, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0672, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0671, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0670, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0669, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0668, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0667, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0666, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0665, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0664, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0663, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0662, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0661, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0660, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0659, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0658, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0657, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# In a training loop, we should perform many GD iterations.\n",
    "n_iter = 1000\n",
    "for i in range(n_iter):\n",
    "    optimizer.zero_grad() # equivalent to net.zero_grad()\n",
    "    output = net(x)\n",
    "    loss = criterion(output,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1869,
     "status": "ok",
     "timestamp": 1599166248524,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "m4gi_ibur2K9",
    "outputId": "d882e696-57ee-44a9-c457-ede56bfd8ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.7690, -1.7035, -1.9214,  0.7850, -2.3263, -2.1545, -2.1495, -2.4258,\n",
      "         -2.2692,  3.8586],\n",
      "        [ 0.3468, -1.5723, -1.6643,  5.7087, -1.5293, -1.7218, -1.5148, -1.6034,\n",
      "         -1.5335,  3.1441],\n",
      "        [ 1.7902, -1.7117, -1.7323,  2.9577, -1.6445, -1.7842, -1.7376, -1.8327,\n",
      "         -1.7686,  5.6042]], grad_fn=<AddmmBackward>)\n",
      "tensor([0, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "output = net(x)\n",
    "print(output)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5brq88Xr2LA"
   },
   "source": [
    "Now you know how to train a network ! For a complete training check the pytorch_example notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Q1nxt_Ir2LA"
   },
   "source": [
    "## Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1862,
     "status": "ok",
     "timestamp": 1599166248525,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "cbJDd3CDr2LB",
    "outputId": "e99415ae-1dac-4c9f-af32-46f25565d048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['0.weight', '0.bias', '2.weight', '2.bias'])\n"
     ]
    }
   ],
   "source": [
    "# get dictionary of keys to weights using `state_dict`\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28,256),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(256,10))\n",
    "print(net.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1851,
     "status": "ok",
     "timestamp": 1599166248525,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "jXuNxlOVr2LG",
    "outputId": "f2d1e033-c092-4db9-cd62-84a7a0a5b550"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save a dictionary\n",
    "torch.save(net.state_dict(),'test.t7')\n",
    "# load a dictionary\n",
    "net.load_state_dict(torch.load('test.t7'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipDjpzYBr2LI"
   },
   "source": [
    "## Common issues to look out for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFuFwGL8r2LK"
   },
   "source": [
    "### Type mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 324,
     "status": "error",
     "timestamp": 1599166274138,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "H_Gu5LsYr2LK",
    "outputId": "751cfad8-424f-4eb1-b2de-0f7f30276525",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-4d1c8f2c4847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out"
     ]
    }
   ],
   "source": [
    "net = nn.Linear(4,2)\n",
    "x = torch.tensor([1,2,3,4])\n",
    "y = net(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1599166278115,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "x2zElZVtr2LN"
   },
   "outputs": [],
   "source": [
    "x = x.float()\n",
    "x = torch.tensor([1.,2.,3.,4.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1599166278117,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "zU06a7Kor2LQ",
    "outputId": "6f029f38-223e-495c-ae80-042ba516f109",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n",
      "tensor([[12., 12.],\n",
      "        [12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x = 2* torch.ones(2,2)\n",
    "y = 3* torch.ones(2,2)\n",
    "print(x * y)\n",
    "print(x.matmul(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "error",
     "timestamp": 1599166278301,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "Z6FlkH01r2LT",
    "outputId": "03018cd0-c4b0-4213-81d0-3e6e1b2804c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5]])\n",
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [4, 4, 4, 4, 4]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-659d2e4e3f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "x = torch.ones(4,5).long()\n",
    "y = torch.arange(5)\n",
    "print(x+y)\n",
    "y = torch.arange(4).view(-1,1)\n",
    "print(x+y)\n",
    "y = torch.arange(4)\n",
    "print(x+y) # exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1599166285834,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "UGoil4F5r2LX",
    "outputId": "e1a853fc-f3b2-467c-9e36-17b000793721"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A note here: You will encounter the following exception a number of times:\n",
    "torch.ones(1, 1) + torch.arange(1) # RuntimeError: expected device cpu and dtype Float but got device cpu and dtype Long\n",
    "#This is because you can't do operations b/n long and float. to fix, either convert both to long or both to float.\n",
    "torch.ones(1, 1) + torch.arange(1).float() # Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1599166285835,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "BkUNRcp6r2Lb",
    "outputId": "7d8f84d9-b2c8-49a4-a058-283a237c9e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "print(x.t())\n",
    "print(x.view(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1599166438840,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "OFKuBQ3Hr2Ld"
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(2048,2048),nn.ReLU(),\n",
    "                   nn.Linear(2048,2048),nn.ReLU(),\n",
    "                   nn.Linear(2048,2048),nn.ReLU(),\n",
    "                   nn.Linear(2048,2048),nn.ReLU(),\n",
    "                   nn.Linear(2048,2048),nn.ReLU(),\n",
    "                   nn.Linear(2048,2048),nn.ReLU(),\n",
    "                   nn.Linear(2048,120))\n",
    "x = torch.ones(256,2048)\n",
    "y = torch.zeros(256).long()\n",
    "net.cuda()\n",
    "x = x.cuda()\n",
    "y = y.cuda()\n",
    "crit=nn.CrossEntropyLoss()\n",
    "out = net(x)\n",
    "loss = crit(out,y)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1599166441000,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "rhI3fBRzr2Lf"
   },
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self,n_hidden_layers):\n",
    "        super(MyNet,self).__init__()\n",
    "        self.n_hidden_layers=n_hidden_layers\n",
    "        self.final_layer = nn.Linear(128,10)\n",
    "        self.act = nn.ReLU()\n",
    "        self.hidden = []\n",
    "        for i in range(n_hidden_layers):\n",
    "            self.hidden.append(nn.Linear(128,128))\n",
    "    \n",
    "            \n",
    "    def forward(self,x):\n",
    "        h = x\n",
    "        for i in range(self.n_hidden_layers):\n",
    "            h = self.hidden[i](h)\n",
    "            h = self.act(h)\n",
    "        out = self.final_layer(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1599166441567,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "gxkgp4wer2Li"
   },
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self,n_hidden_layers):\n",
    "        super(MyNet,self).__init__()\n",
    "        self.n_hidden_layers=n_hidden_layers\n",
    "        self.final_layer = nn.Linear(128,10)\n",
    "        self.act = nn.ReLU()\n",
    "        self.hidden = []\n",
    "        for i in range(n_hidden_layers):\n",
    "            self.hidden.append(nn.Linear(128,128))\n",
    "        self.hidden = nn.ModuleList(self.hidden)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        h = x\n",
    "        for i in range(self.n_hidden_layers):\n",
    "            h = self.hidden[i](h)\n",
    "            h = self.act(h)\n",
    "        out = self.final_layer(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "aborted",
     "timestamp": 1599166286456,
     "user": {
      "displayName": "Jinhyung Park",
      "photoUrl": "",
      "userId": "09175722141184945998"
     },
     "user_tz": 240
    },
    "id": "aqXgOxIDr2Lm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5z5CoVzTr2Jc",
    "ks9_voC4r2Jt",
    "W_1cyRkXr2J1",
    "n6L5DTqCr2KH",
    "gZ01AInyr2KY",
    "hlO8kwqGr2Kp",
    "1Q1nxt_Ir2LA",
    "hFuFwGL8r2LK"
   ],
   "name": "Tutorial-pytorch_F19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}